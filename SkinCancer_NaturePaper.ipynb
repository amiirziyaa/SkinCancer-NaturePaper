{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c436c5",
      "metadata": {
        "id": "d9c436c5"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets mahotas scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SSb-TPm6B9au"
      },
      "id": "SSb-TPm6B9au",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c145f7d5",
      "metadata": {
        "id": "c145f7d5"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import mahotas  # for Haralick Texture\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b3e80e",
      "metadata": {
        "id": "12b3e80e"
      },
      "source": [
        "Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "Set the path to save model weights in Google Drive\n",
        "checkpoint_dir = '/content/drive/MyDrive/nature/'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pzEkgKboCY4D"
      },
      "id": "pzEkgKboCY4D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bada050",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "8bada050"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "dataset_url = \"https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000\"\n",
        "od.download(dataset_url)\n",
        "base_dir = './skin-cancer-mnist-ham10000/'\n",
        "image_dir_1 = './skin-cancer-mnist-ham10000/HAM10000_images_part_1'\n",
        "image_dir_2 = './skin-cancer-mnist-ham10000/HAM10000_images_part_2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60531a50",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "60531a50"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess grayscale images\n",
        "def load_and_preprocess_grayscale_image(image_id, img_size=(224, 224)):\n",
        "    img_path_1 = os.path.join(image_dir_1, f'{image_id}.jpg')\n",
        "    img_path_2 = os.path.join(image_dir_2, f'{image_id}.jpg')\n",
        "\n",
        "    if os.path.exists(img_path_1):\n",
        "        img = cv2.imread(img_path_1)\n",
        "    elif os.path.exists(img_path_2):\n",
        "        img = cv2.imread(img_path_2)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Image {image_id}.jpg not found in either folder.\")\n",
        "\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_gray = cv2.resize(img_gray, img_size)\n",
        "    img_gray = img_gray / 255.0  # Normalize to [0, 1]\n",
        "    img_gray = np.expand_dims(img_gray, axis=-1)  # Shape (224, 224, 1)\n",
        "\n",
        "    return img_gray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056ef0c7",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "056ef0c7"
      },
      "outputs": [],
      "source": [
        "# Compute Hu Moments (Shape Feature)\n",
        "def compute_hu_moments(img_gray):\n",
        "    moments = cv2.moments(img_gray)\n",
        "    hu_moments = cv2.HuMoments(moments)\n",
        "    hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-12)\n",
        "    return hu_moments.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d39c47d",
      "metadata": {
        "id": "8d39c47d"
      },
      "outputs": [],
      "source": [
        "# Compute Haralick Texture (Texture Feature)\n",
        "def compute_haralick_texture(img_gray):\n",
        "    img_quantized = (img_gray * 255).astype(np.uint8)\n",
        "    haralick = mahotas.features.haralick(img_quantized).mean(axis=0)\n",
        "    return haralick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583a3b50",
      "metadata": {
        "id": "583a3b50"
      },
      "outputs": [],
      "source": [
        "# Load metadata\n",
        "metadata_path = base_dir + 'HAM10000_metadata.csv'\n",
        "metadata = pd.read_csv(metadata_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ecc984",
      "metadata": {
        "id": "75ecc984"
      },
      "outputs": [],
      "source": [
        "# Map labels to numeric values\n",
        "label_map = {label: idx for idx, label in enumerate(metadata['dx'].unique())}\n",
        "metadata['label'] = metadata['dx'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c445f45",
      "metadata": {
        "id": "0c445f45"
      },
      "outputs": [],
      "source": [
        "# Get 100 images from each class\n",
        "sampled_metadata = metadata.groupby('label').apply(lambda x: x.sample(n=100, random_state=42)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e189e0",
      "metadata": {
        "id": "02e189e0"
      },
      "outputs": [],
      "source": [
        "# Perform offline data augmentation to create 100 more images for each class\n",
        "augmentation_datagen = ImageDataGenerator(\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d913c5",
      "metadata": {
        "id": "e6d913c5"
      },
      "outputs": [],
      "source": [
        "augmented_images = []\n",
        "augmented_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fbf6bb0",
      "metadata": {
        "id": "4fbf6bb0"
      },
      "outputs": [],
      "source": [
        "for _, row in sampled_metadata.iterrows():\n",
        "    image_id = row['image_id']\n",
        "    label = row['label']\n",
        "    img_gray = load_and_preprocess_grayscale_image(image_id, img_size=(96, 96))\n",
        "    img_gray = np.expand_dims(img_gray, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Generate 100 augmented images for each original image\n",
        "    i = 0\n",
        "    for batch in augmentation_datagen.flow(img_gray, batch_size=1):\n",
        "        augmented_images.append(batch[0])\n",
        "        augmented_labels.append(label)\n",
        "        i += 1\n",
        "        if i >= 80:  # Stop after generating 100 images\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5faf5dd2",
      "metadata": {
        "id": "5faf5dd2"
      },
      "outputs": [],
      "source": [
        "# Convert augmented data to numpy arrays\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0cb47f",
      "metadata": {
        "id": "5a0cb47f"
      },
      "outputs": [],
      "source": [
        "# Convert labels to one-hot encoding\n",
        "augmented_labels = tf.keras.utils.to_categorical(augmented_labels, num_classes=len(label_map))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "835ab387",
      "metadata": {
        "id": "835ab387"
      },
      "outputs": [],
      "source": [
        "# Split augmented data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    augmented_images, augmented_labels, test_size=0.2, random_state=42, stratify=augmented_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5060992a",
      "metadata": {
        "id": "5060992a"
      },
      "outputs": [],
      "source": [
        "# Further split test data into validation and final test sets (50% each)\n",
        "X_val, X_final_test, y_val, y_final_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f856359",
      "metadata": {
        "id": "4f856359"
      },
      "outputs": [],
      "source": [
        "# Model structure\n",
        "input_gray = tf.keras.layers.Input(shape=(96, 96, 1), name='gray_input')\n",
        "input_hu = tf.keras.layers.Input(shape=(7,), name='hu_moments_input')\n",
        "input_haralick = tf.keras.layers.Input(shape=(13,), name='haralick_texture_input')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b651cca5",
      "metadata": {
        "id": "b651cca5"
      },
      "outputs": [],
      "source": [
        "# gray image processing branch\n",
        "x = tf.keras.layers.BatchNormalization()(input_gray)\n",
        "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((3, 3))(x)\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "x = tf.keras.layers.Flatten()(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7530432e",
      "metadata": {
        "id": "7530432e"
      },
      "outputs": [],
      "source": [
        "# Hu and Haralick features branches\n",
        "hu_features = tf.keras.layers.Dense(32, activation='relu')(input_hu)\n",
        "hu_features = tf.keras.layers.BatchNormalization()(hu_features)\n",
        "haralick_features = tf.keras.layers.Dense(32, activation='relu')(input_haralick)\n",
        "haralick_features = tf.keras.layers.BatchNormalization()(haralick_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af0f5c45",
      "metadata": {
        "id": "af0f5c45"
      },
      "outputs": [],
      "source": [
        "# Combine features\n",
        "combined_features = tf.keras.layers.concatenate([x, hu_features, haralick_features])\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(combined_features)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "output = tf.keras.layers.Dense(len(label_map), activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5f5d02",
      "metadata": {
        "id": "3e5f5d02"
      },
      "outputs": [],
      "source": [
        "# Model definition\n",
        "model = tf.keras.Model(inputs=[input_gray, input_hu, input_haralick], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31e88e4c",
      "metadata": {
        "id": "31e88e4c"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hu_haralick_features(X):\n",
        "    hu = []\n",
        "    haralick = []\n",
        "    for img in X:\n",
        "        img2d = img.squeeze()\n",
        "        hu.append(compute_hu_moments(img2d))\n",
        "        haralick.append(compute_haralick_texture(img2d))\n",
        "    return np.array(hu), np.array(haralick)\n",
        "\n",
        "X_train_hu, X_train_haralick = extract_hu_haralick_features(X_train)\n",
        "X_val_hu, X_val_haralick = extract_hu_haralick_features(X_val)\n",
        "X_final_test_hu, X_final_test_haralick = extract_hu_haralick_features(X_final_test)\n"
      ],
      "metadata": {
        "id": "lIgZeYoa6uEq"
      },
      "id": "lIgZeYoa6uEq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "478c144b",
      "metadata": {
        "id": "478c144b"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    [X_train, X_train_hu, X_train_haralick],\n",
        "    y_train,\n",
        "    validation_data=([X_val, X_val_hu, X_val_haralick], y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Test\n",
        "y_pred_prob = model.predict([X_final_test, X_final_test_hu, X_final_test_haralick])\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(y_final_test, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8e4dc7",
      "metadata": {
        "id": "cf8e4dc7"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the final test set\n",
        "y_pred_prob = model.predict([X_final_test, np.zeros((X_final_test.shape[0], 7)), np.zeros((X_final_test.shape[0], 13))])\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(y_final_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b22403",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "64b22403"
      },
      "outputs": [],
      "source": [
        "# Compute precision, recall, f1-score\n",
        "report = classification_report(y_true, y_pred, target_names=label_map.keys())\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "164fd6ad",
      "metadata": {
        "id": "164fd6ad"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}